{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180973dc-a4fc-43aa-bbc5-d56ce3e9edba",
   "metadata": {},
   "source": [
    "# Virtualizarr Useful Recipes with NASA Earthdata\n",
    "\n",
    "#### *Author: Dean Henze, PO.DAAC*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e719d0-17d1-45e9-9933-cb49a7cef7a9",
   "metadata": {},
   "source": [
    "Testing the creation of virtual reference files using `kerchunk` vs `virtualizarr`. Currently, we're seeing that opening a data set using a ref file made with `virtualizarr` takes much longer than using a ref file made with `kerchunk`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f65dd1-39f6-480a-aa63-adbbd9863e8f",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "#### ***Note Zarr Version***\n",
    "***Zarr version 2 is needed for the current implementation of this notebook, due to (as of February 2025) Zarr version 3 not accepting `FSMap` objects.***\n",
    "\n",
    "We ran this notebook in a Python 3.12 environment. The minimal working install we used to run this notebook from a clean environment was:\n",
    "```\n",
    "pip install zarr==2.18.4 fastparquet==2024.5.0 xarray==2025.1.2 earthaccess==0.11.0 fsspec==2024.10.0 \"dask[complete]\"==2024.5.2 h5netcdf==1.3.0 ujson==5.10.0 matplotlib==3.9.2 jupyterlab jupyter-server-proxy virtualizarr==1.3.0\n",
    "```\n",
    "And optionally:\n",
    "```\n",
    "pip install coiled==1.58.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0b1c0c-c8f9-412c-8038-4b674de896c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in packages\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Filesystem management \n",
    "import fsspec\n",
    "import earthaccess\n",
    "\n",
    "# Data analysis\n",
    "import xarray as xr\n",
    "from virtualizarr import open_virtual_dataset\n",
    "\n",
    "# Parallel computing \n",
    "import multiprocessing\n",
    "from dask import delayed\n",
    "import dask.array as da\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Other\n",
    "import ujson\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e601488-7348-45cb-bfed-068121fc4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e58626-85f4-4fed-b5af-04736ca6f83d",
   "metadata": {},
   "source": [
    "## Other Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c5a123-6025-4a85-a7b0-4b9b747a9a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7fea96d30980>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.set_options( # display options for xarray objects\n",
    "    display_expand_attrs=False,\n",
    "    display_expand_coords=True,\n",
    "    display_expand_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901e7c4-66ca-4dfb-bd8f-aaf2f0291764",
   "metadata": {},
   "source": [
    "## 1. Get Data File S3 endpoints in Earthdata Cloud \n",
    "The first step is to find the S3 endpoints to the files. Handling access credentials to Earthdata and then finding the endpoints can be done a number of ways (e.g. using the `requests`, `s3fs` packages) but we use the `earthaccess` package for its ease of use. We get the endpoints for all files in the CCMP record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dbc070-d5f7-407e-b92e-4fda1b8a82ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Earthdata Login username:  deanh808\n",
      "Enter your Earthdata password:  ········\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x7feaec06c590>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Earthdata creds\n",
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7519aab1-b2aa-40fa-862a-62ed69439ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AWS creds. Note that if you spend more than 1 hour in the notebook, you may have to re-run this line!!!\n",
    "fs = earthaccess.get_s3_filesystem(daac=\"PODAAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487b4dd6-39c6-4d7e-8051-eddcd22e2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate CCMP file information / metadata:\n",
    "granule_info = earthaccess.search_data(\n",
    "    short_name=\"OSTIA-UKMO-L4-GLOB-REP-v2.0\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc311a3-df1a-4565-a314-658bff759203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://podaac-ops-cumulus-protected/OSTIA-UKMO-L4-GLOB-REP-v2.0/1982/001/19820101120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB_REP-v02.0-fv02.0.nc',\n",
       " 's3://podaac-ops-cumulus-protected/OSTIA-UKMO-L4-GLOB-REP-v2.0/1982/002/19820102120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB_REP-v02.0-fv02.0.nc',\n",
       " 's3://podaac-ops-cumulus-protected/OSTIA-UKMO-L4-GLOB-REP-v2.0/1982/003/19820103120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB_REP-v02.0-fv02.0.nc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get S3 endpoints for all files:\n",
    "data_s3links = [g.data_links(access=\"direct\")[0] for g in granule_info]\n",
    "data_s3links[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e33a1a-bd28-4b60-b411-18e25c7cb1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/OSTIA-UKMO-L4-GLOB-REP-v2.0/1982/001/19820101120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB_REP-v02.0-fv02.0.nc',\n",
       " 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/OSTIA-UKMO-L4-GLOB-REP-v2.0/1982/002/19820102120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB_REP-v02.0-fv02.0.nc',\n",
       " 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/OSTIA-UKMO-L4-GLOB-REP-v2.0/1982/003/19820103120000-UKMO-L4_GHRSST-SSTfnd-OSTIA-GLOB_REP-v02.0-fv02.0.nc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get HTTPS endpoints for all files:\n",
    "data_httpslinks = [g.data_links(access=\"external\")[0] for g in granule_info]\n",
    "data_httpslinks[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20756ad2-4fdf-4f7a-8582-aa7d59ea35e5",
   "metadata": {},
   "source": [
    "## 2. Generate reference file entire record using virtualizarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329db221-b2dc-41de-8e67-3405402e4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_opts = {\"storage_options\": fs.storage_options} # S3 filesystem creds from previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15707ccc-fcb3-4bf9-94cb-71b11d468054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data using the reference file, using a small wrapper function around xarray's open_dataset. \n",
    "# This will shorten code blocks in other sections. \n",
    "def opendf_withref(ref, fs_data):\n",
    "    \"\"\"\n",
    "    \"ref\" is a reference file or object. \"fs_data\" is a filesystem with credentials to\n",
    "    access the actual data files. \n",
    "    \"\"\"\n",
    "    storage_opts = {\"fo\": ref, \"remote_protocol\": \"s3\", \"remote_options\": fs_data.storage_options}\n",
    "    fs_ref = fsspec.filesystem('reference', **storage_opts)\n",
    "    m = fs_ref.get_mapper('')\n",
    "    data = xr.open_dataset(\n",
    "        m, engine=\"zarr\", chunks={},\n",
    "        backend_kwargs={\"consolidated\": False}\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083114d-de86-4860-911f-f44e21877725",
   "metadata": {},
   "source": [
    "### Parallelize using distributed cluster with Coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa76bec-1ef7-4ed1-bc58-f16eea3aa9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a203bbea0a469d96ba209d405db633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8f7e48f6084ce799bae1d0628bad98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 801 ms, total: 11.4 s\n",
      "Wall time: 8min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## --------------------------------------------\n",
    "## Create single reference files with parallel computing using Coiled\n",
    "## --------------------------------------------\n",
    "\n",
    "# Wrap `open_virtual_dataset()` into coiled function and copy to mulitple VM's:\n",
    "open_vds_par = coiled.function(\n",
    "    region=\"us-west-2\", spot_policy=\"on-demand\", \n",
    "    vm_type=\"m6i.large\", n_workers=30\n",
    "    )(open_virtual_dataset)\n",
    "\n",
    "# Begin computations:\n",
    "results = open_vds_par.map(data_s3links[:], indexes={}, reader_options=reader_opts)\n",
    "\n",
    "virtual_ds_list = []\n",
    "for r in results:\n",
    "    virtual_ds_list.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0c311a-9523-44d4-96eb-b88db5bda632",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_vds_par.cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d5580-472d-4525-994f-32e96bf85293",
   "metadata": {},
   "source": [
    "Using the individual references to create the combined reference is fast and does not requre parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca199351-8ea0-47a5-99e7-483bc8c75f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 s, sys: 124 ms, total: 8.12 s\n",
      "Wall time: 8.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Combining the individual references works the same as in Section 2.2.1:\n",
    "virtual_ds_combined = xr.combine_nested(virtual_ds_list, concat_dim='time', coords='minimal', compat='override', combine_attrs='drop_conflicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc631c2-4747-46ce-866f-e406ca298aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in JSON or PARQUET format:\n",
    "fname_combined_json = 'OSTIA-UKMO-L4-GLOB-REP-v2.0_reffile_virtualizarr.json'\n",
    "fname_combined_parq = 'OSTIA-UKMO-L4-GLOB-REP-v2.0_reffile_virtualizarr.parq'\n",
    "virtual_ds_combined.virtualize.to_kerchunk(fname_combined_json, format='json')\n",
    "virtual_ds_combined.virtualize.to_kerchunk(fname_combined_parq, format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af082915-cb86-4e9d-8800-20287f8528dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 11TB\n",
      "Dimensions:           (time: 15340, lat: 3600, lon: 7200)\n",
      "Coordinates:\n",
      "  * lat               (lat) float32 14kB -89.97 -89.93 -89.88 ... 89.93 89.97\n",
      "  * lon               (lon) float32 29kB -180.0 -179.9 -179.9 ... 179.9 180.0\n",
      "  * time              (time) datetime64[ns] 123kB 1982-01-01T12:00:00 ... 202...\n",
      "Data variables:\n",
      "    analysed_sst      (time, lat, lon) float64 3TB dask.array<chunksize=(1, 1200, 2400), meta=np.ndarray>\n",
      "    analysis_error    (time, lat, lon) float64 3TB dask.array<chunksize=(1, 1200, 2400), meta=np.ndarray>\n",
      "    mask              (time, lat, lon) float32 2TB dask.array<chunksize=(1, 1800, 3600), meta=np.ndarray>\n",
      "    sea_ice_fraction  (time, lat, lon) float64 3TB dask.array<chunksize=(1, 1800, 3600), meta=np.ndarray>\n",
      "Attributes: (39)\n",
      "CPU times: user 54.4 s, sys: 814 ms, total: 55.2 s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test lazy loading of the combine reference file JSON:\n",
    "data_json = opendf_withref(fname_combined_json, fs)\n",
    "print(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e315d3-bd54-4c94-b993-33c69ab8fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 11TB\n",
      "Dimensions:           (time: 15340, lat: 3600, lon: 7200)\n",
      "Coordinates:\n",
      "  * lat               (lat) float32 14kB -89.97 -89.93 -89.88 ... 89.93 89.97\n",
      "  * lon               (lon) float32 29kB -180.0 -179.9 -179.9 ... 179.9 180.0\n",
      "  * time              (time) datetime64[ns] 123kB 1982-01-01T12:00:00 ... 202...\n",
      "Data variables:\n",
      "    analysed_sst      (time, lat, lon) float64 3TB dask.array<chunksize=(1, 1200, 2400), meta=np.ndarray>\n",
      "    analysis_error    (time, lat, lon) float64 3TB dask.array<chunksize=(1, 1200, 2400), meta=np.ndarray>\n",
      "    mask              (time, lat, lon) float32 2TB dask.array<chunksize=(1, 1800, 3600), meta=np.ndarray>\n",
      "    sea_ice_fraction  (time, lat, lon) float64 3TB dask.array<chunksize=(1, 1800, 3600), meta=np.ndarray>\n",
      "Attributes: (39)\n",
      "CPU times: user 52.5 s, sys: 621 ms, total: 53.1 s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test lazy loading of the combine reference file PARQUET:\n",
    "data_parq = opendf_withref(fname_combined_parq, fs)\n",
    "print(data_parq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa9442-41eb-4b5f-bac2-51a39b78f7de",
   "metadata": {},
   "source": [
    "## 3. Generate reference file entire record using kerchunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7498133-0167-48dc-95fd-7280cdb67856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerchunk.df import refs_to_dataframe\n",
    "from kerchunk.hdf import SingleHdf5ToZarr\n",
    "from kerchunk.combine import MultiZarrToZarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a98824-456d-4185-a0d0-69120c424da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae171dff12c4ed0b5eec4559500a15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/15340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447b414941dc48008f9eb1c0ed01f9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/15340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a5da7a4ba3410eaa542197ea857036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/15340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fobjs = earthaccess.open(granule_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40fc16ea-35ba-44ce-8a30-eaba70205085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_ref_earthaccess(fobj, dir_save=None):\n",
    "    \"\"\"\n",
    "    Create a reference for a single data file. \"fobj\" (earthaccess.store.EarthAccessFile \n",
    "    object) is the output from earthaccess.open(), which also has the file endpoint. \n",
    "    Option to save as a JSON to direcotry \"dir_save\", with file name of the corresponding \n",
    "    data file with \".json\" appended. Otherwise reference info is returned.\n",
    "    \"\"\"\n",
    "    endpoint = fobj.full_name\n",
    "    reference = SingleHdf5ToZarr(fobj, endpoint, inline_threshold=0).translate()\n",
    "    \n",
    "    if dir_save is not None:\n",
    "        with open(dir_save + endpoint.split('/')[-1]+'.json', 'w') as outf:\n",
    "            outf.write(ujson.dumps(reference))\n",
    "    else:\n",
    "        return reference, endpoint # returns both the kerchunk reference and the path the file on podaac-ops-cumulus-protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fed567e-40c9-4752-862c-5424de59aed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e23083d904a519c9feaff44433173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f66723332345f995e50675825f8028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 116 ms, total: 3.08 s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## --------------------------------------------\n",
    "## Create single reference files with parallel computing using Coiled\n",
    "## --------------------------------------------\n",
    "\n",
    "# Wrap `create_single_ref` into coiled function:\n",
    "single_ref_earthaccess_par = coiled.function(\n",
    "    region=\"us-west-2\", spot_policy=\"on-demand\", \n",
    "    vm_type=\"m6i.large\", n_workers=16\n",
    "    )(single_ref_earthaccess)\n",
    "\n",
    "# Begin computations:\n",
    "results = single_ref_earthaccess_par.map(fobjs[:365])\n",
    "\n",
    "# Append results as they become available:\n",
    "virtual_ref_list = []\n",
    "for r, ep in results:\n",
    "    virtual_ref_list.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59080df-ff96-4472-8e97-1e434235893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ref_earthaccess_par.cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2b8f528-f3d3-4efd-a7c6-3d3f2fb10bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 190 ms, total: 2.73 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## --------------------------------------------\n",
    "## Create combined reference file\n",
    "## --------------------------------------------\n",
    "## Combined reference file\n",
    "kwargs_mzz = {'remote_protocol':\"s3\", 'remote_options':fs.storage_options, 'concat_dims':[\"time\"]}\n",
    "mzz = MultiZarrToZarr(virtual_ref_list, **kwargs_mzz)\n",
    "ref_combined = mzz.translate()\n",
    "\n",
    "refs_to_dataframe(ref_combined, \"OSTIA-UKMO-L4-GLOB-REP-v2.0_reffile_kerchunk.parq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
